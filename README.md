# Whisper Transcription Playground


A simple playground for experimenting with [OpenAI Whisper](https://github.com/openai/whisper) speech-to-text models.

## Features

- ğŸ™ï¸ Transcribe audio files (.wav, `.mp3, `.m4a, `etc.)
- ğŸ”¤ Automatic language detection
- ğŸ§  Support for multiple Whisper models (tiny â†’ large)
- ğŸ“„ Export transcripts to .`txt,` .`srt,` and .`vtt `subtitle formats

## ğŸ”¬ Experiments


This project explores how Whisperâ€™s parameters affect transcription:


- âœ… Basic transcription (`transcribe.py`)
- âœ… Translation mode (`translate.py`)
- ğŸ”„ Parameter Testing:
	- Beam Search vs Greedy Decoding
	- Temperature fallback
	- Word-level timestamps
	- Silence & confidence thresholds
	- Initial prompt for domain adaptation


----

## Setup


### 1. Clone the repository


`git clone https://github.com/martin-sack/Whisper-Transcription-Playground.git cd Whisper-Transcription-Playground`

### 2. Create and activate a virtual environment


`python3 -m venv whisper-env 
source whisper-env/bin/activate   # macOS/Linux 
# .\whisper-env\Scripts\activate  # Windows PowerShell`

### 3. Install dependencies


## `pip install -r requirements.txt`


## Usage


## Run Whisper on an audio file:  
`whisper samples/a0286.wav --model base --output_dir results/`  
# Results will be saved in the `results/` folder as `.txt`, `.srt`, and `.vtt` files.


## Audio Samples


You can download the original audio files used for transcription here:
- [a0286.wav](samples/a0286.wav)
- [a0287.wav](samples/a0287.wav)
- [a0288.wav](samples/a0288.wav)
- [a0289.wav](samples/a0289.wav)
- [a0290.wav](samples/a0290.wav)
- [a0292.wav](samples/a0292.wav)
- [a0294.wav](samples/a0294.wav)
- [a0295.wav](samples/a0295.wav)
----

## Requirements

- Python 3.9+
- ffmpeg installed and available in your PATH
- A GPU (optional, but recommended for faster transcription)


----

## License


MIT License Â© 2025
